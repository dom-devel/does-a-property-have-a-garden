{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "from requests.utils import quote\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib.parse import urlparse\n",
    "import copy \n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrying import retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "We start by setting up Chromedriver.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "prefs = {\n",
    "    \"download.default_directory\": os.getcwd(),\n",
    "    \"executable_path\": r\"C:\\Users\\Dom_W\\Documents\\Development\\Selenium\\chromedriver.exe\",\n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# I have created special user profile for scraping it won't open existing one.\n",
    "options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Dom_W\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\\\\Profile 6\"\n",
    ")  # Path to your chrome profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boot up Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chrome_options=options)\n",
    "# You might need to update ChromeDriver here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_href_from_list_of_elements(element_list):\n",
    "    if isinstance(element_list, list):\n",
    "        return [element.get_attribute(\"href\") for element in element_list]\n",
    "    return element_list.get_attribute(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_list_of_elements(element_list):\n",
    "    if isinstance(element_list, list):\n",
    "        return [element.text for element in element_list]\n",
    "    return element_list.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do two things. We need to crawl and to scape. We can separate those two things out. \n",
    "\n",
    "We're going to use Selenium to get around any crawl protection as it will just prompt me and I can fill it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_we_end_pagination(driver,ending_class):\n",
    "    # Check if we've reached the end. If we have then time to bail.\n",
    "    try:\n",
    "        end_button = driver.find_element_by_css_selector(ending_class)\n",
    "        return True\n",
    "    except NoSuchElementException as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_properties(driver, output_list):\n",
    "    # All property elements\n",
    "    all_properties = driver.find_elements_by_css_selector(\n",
    "        \".propertyCard-details .propertyCard-link\"\n",
    "    )\n",
    "\n",
    "    # Get links\n",
    "    all_property_hrefs = extract_href_from_list_of_elements(all_properties)\n",
    "\n",
    "    # Dump into the output list.\n",
    "    output_list.extend(all_property_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_and_extract(output_list):\n",
    "    # Make sure the page is loaded.\n",
    "\n",
    "    # Page loads with ajax on subsequent clicks so we need to wait for loading.\n",
    "\n",
    "    # If it presents a captcha solve in the 20 seconds you've got.\n",
    "    for x in range(40):\n",
    "        WebDriverWait(driver, 20).until_not(\n",
    "            EC.text_to_be_present_in_element(\n",
    "                (By.CSS_SELECTOR, \".propertyCard-title\"), \"Loading Property\"\n",
    "            )\n",
    "        )\n",
    "    extract_properties(driver, output_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run the crawl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_search = \"https://www.rightmove.co.uk/property-to-rent/find.html?propertyTypes=flat&keywords=&includeLetAgreed=false&dontShow=houseShare%2Cretirement&channel=RENT&index=0&mustHave=garden&primaryDisplayPropertyType=flats&retirement=false&houseFlatShare=false&maxBedrooms=2&sortType=6&minPrice=1000&viewType=LIST&maxPrice=1750&radius=0.0&propFeature=Garden&locationIdentifier=REGION%5E87490\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(starting_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_output_list = []\n",
    "more_pages = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1.\n",
      "Extracting page.\n",
      "Page 2.\n",
      "Extracting page.\n",
      "Page 3.\n",
      "Extracting page.\n",
      "Page 4.\n",
      "Extracting page.\n",
      "Page 5.\n",
      "Extracting page.\n",
      "Page 6.\n",
      "Extracting page.\n",
      "Page 7.\n",
      "Extracting page.\n",
      "Page 8.\n",
      "Extracting page.\n",
      "Page 9.\n",
      "Extracting page.\n",
      "Page 10.\n",
      "Extracting page.\n",
      "Page 11.\n",
      "Extracting page.\n",
      "Page 12.\n",
      "Extracting page.\n",
      "Page 13.\n",
      "Extracting page.\n",
      "Page 14.\n",
      "Extracting page.\n",
      "Page 15.\n",
      "Extracting page.\n",
      "Page 16.\n",
      "Extracting page.\n",
      "Page 17.\n",
      "Extracting page.\n",
      "Page 18.\n",
      "Extracting page.\n",
      "Page 19.\n",
      "Extracting page.\n",
      "Page 20.\n",
      "Extracting page.\n",
      "Page 21.\n",
      "Extracting page.\n",
      "Page 22.\n",
      "Extracting page.\n",
      "Page 23.\n",
      "Extracting page.\n",
      "Page 24.\n",
      "Extracting page.\n",
      "Page 25.\n",
      "Extracting page.\n",
      "Page 26.\n",
      "Extracting page.\n",
      "Page 27.\n",
      "Extracting page.\n",
      "Page 28.\n",
      "Extracting page.\n",
      "Page 29.\n",
      "Extracting page.\n",
      "Page 30.\n",
      "Extracting page.\n",
      "Page 31.\n",
      "Extracting page.\n",
      "Page 32.\n",
      "Extracting page.\n",
      "Page 33.\n",
      "Extracting page.\n",
      "Page 34.\n",
      "Extracting page.\n",
      "Page 35.\n",
      "Extracting page.\n",
      "Page 36.\n",
      "Extracting page.\n",
      "Page 37.\n",
      "Extracting page.\n",
      "Page 38.\n",
      "Extracting page.\n",
      "Page 39.\n",
      "Extracting page.\n",
      "Page 40.\n",
      "Extracting page.\n",
      "Page 41.\n",
      "Extracting page.\n",
      "Page 42.\n",
      "Extracting page.\n",
      "Page 43.\n",
      "Extracting page.\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "while more_pages:\n",
    "    print(\"Page {}.\".format(counter))\n",
    "    \n",
    "    # We wrap this in generic error handling because selenium just loves to fail\n",
    "    # for weird reasons.\n",
    "    print(\"Extracting page.\")\n",
    "    crawl_and_extract(property_output_list)    \n",
    "\n",
    "    # Then got to the next page.\n",
    "    driver.find_element_by_css_selector(\".pagination-direction--next\").click()\n",
    "\n",
    "    # A quick sleep to look slightly less suspicious\n",
    "    time.sleep(2)\n",
    "    \n",
    "    counter+= 1\n",
    "    \n",
    "    # Time to stop?\n",
    "    if do_we_end_pagination(driver, \"button.pagination-direction--next[disabled]\"):\n",
    "        extract_properties(driver, property_output_list)\n",
    "        break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(property_output_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_to_extract_list(driver, css_selector):\n",
    "    try:\n",
    "        output = extract_text_from_list_of_elements(\n",
    "            driver.find_elements_by_css_selector(css_selector)\n",
    "        )\n",
    "    except NoSuchElementException as e:\n",
    "        print(e)\n",
    "        output = []\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_to_extract_str(driver, css_selector):\n",
    "    try:\n",
    "        output = driver.find_element_by_css_selector(css_selector).text\n",
    "    except NoSuchElementException as e:\n",
    "        print(e)\n",
    "        output = []\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(url):\n",
    "    # No ajax cleverness here. Just all the reqs. The webdriver inbuilt wait\n",
    "    # is pretty great.\n",
    "    driver.get(url)\n",
    "\n",
    "    # We'll put our wait to be less suspicious and be patient here.\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Now we get all the stuff we want:\n",
    "    price = try_to_extract_str(driver, current_rm_css_class[\"price\"])\n",
    "    address = try_to_extract_str(driver, current_rm_css_class[\"address\"])\n",
    "    \n",
    "    # No way to filter with CSS so we do it with python.\n",
    "    all_property_aspects = try_to_extract_list(driver, current_rm_css_class[\"bedrooms\"])\n",
    "    bedrooms = next(filter(lambda i: re.search(\"bedroom\", i, re.IGNORECASE), all_property_aspects))\n",
    "    \n",
    "    # Key features is often missing.\n",
    "    key_features = try_to_extract_list(driver, current_rm_css_class[\"key_features\"])\n",
    "    property_description = try_to_extract_str(driver, current_rm_css_class[\"property_description\"])\n",
    "    \n",
    "    # Stitch together stations for easier parsing\n",
    "    nearby_stations = try_to_extract_list(driver, current_rm_css_class[\"nearby_stations_name\"])\n",
    "    nearby_stations_distance = try_to_extract_list(driver, current_rm_css_class[\"nearby_stations_distance\"])\n",
    "    \n",
    "    nearby_station_zip = list(zip(nearby_stations, nearby_stations_distance))\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"url\":rm_property,\n",
    "        \"price\": price,\n",
    "        \"address\": address,\n",
    "        \"bedrooms\": bedrooms,\n",
    "        \"key_features\": key_features,\n",
    "        \"property_description\": property_description,\n",
    "        \"nearby_stations\": nearby_station_zip,\n",
    "        \"nearest_station\": nearby_station_zip[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_rm_css_class = {\n",
    "    \"price\": \"._1gfnqJ3Vtd1z40MlC0MzXu\",\n",
    "    \"address\": 'h1[itemprop=\"streetAddress\"]',\n",
    "    \"bedrooms\": \"._1u12RxIYGx3c84eaGxI6_b\",\n",
    "    \"key_features\": \".lIhZ24u1NHMa5Y6gDH90A\",\n",
    "    \"property_description\": \".OD0O7FWw1TjbTD4sdRi1_\",\n",
    "    \"nearby_stations_name\": \".cGDiWU3FlTjqSs-F1LwK4\",\n",
    "    \"nearby_stations_distance\": \"._1ZY603T1ryTT3dMgGkM7Lg\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_property_data_scrape = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rm_property in property_output_list:\n",
    "    try:\n",
    "        print(\"Scraping: {}\".format(rm_property))\n",
    "        properties = extract_data(rm_property)\n",
    "        output_property_data_scrape.append(properties)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backup for when Windows decides to randomly update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('property_details_2.json', 'w') as outfile:\n",
    "    json.dump(output_property_data_scrape, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(output_property_data_scrape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief bit of post processing to find our gardens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['key_features_str'] = df['key_features'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dom_W\\anaconda3\\lib\\site-packages\\pandas\\core\\strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df['has_garden_private'] = (df['key_features_str'].str.contains(r\"(shared|private) [Gg]arden\\b\") | df['property_description'].str.contains(r\"(shared|private) [Gg]arden\\b\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 40% don't actually have gardens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    851\n",
       "True     126\n",
       "Name: has_garden_private, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['has_garden_private'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"output_property_details_flats_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
